<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Two-Level Monte Carlo estimator leveraging Neural Incident Radiance Cache (NIRC) for real-time global illumination rendering. A novel approach combining neural networks with Monte Carlo methods for efficient real-time path tracing.">
  <meta name="keywords" content="Neural Rendering, Global Illumination, Path Tracing, Monte Carlo, Neural Incident Radiance Cache, Real-time Rendering, Computer Graphics, Eurographics 2025, KIT, Karlsruhe Institute of Technology">
  <meta name="author" content="Mikhail Dereviannykh, Dmitrii Klepikov, Johannes Hanika, Carsten Dachsbacher">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:title" content="Neural Two-Level Monte Carlo Real-Time Rendering"/>
  <meta property="og:description" content="Efficient real-time global illumination rendering using Neural Incident Radiance Cache combined with Two-Level Monte Carlo. By Mikhail Dereviannykh, Dmitrii Klepikov, Johannes Hanika, and Carsten Dachsbacher from Karlsruhe Institute of Technology (KIT).">
  <meta property="og:url" content="https://mishok43.github.io/nirc"/>
  <meta property="og:image" content="https://mishok43.github.io/nirc/static/images/TeaserNew.jpg"/>
  <meta property="og:video" content="https://www.youtube.com/embed/Y791SlodLOs" />
  <meta property="og:video:type" content="text/html" />
  <meta property="og:video:width" content="1280"/>
  <meta property="og:video:height" content="720"/>

  <!-- Twitter -->
  <meta name="twitter:title" content="Neural Two-Level Monte Carlo Real-Time Rendering">
  <meta name="twitter:description" content="Efficient real-time global illumination rendering using Neural Incident Radiance Cache combined with Two-Level Monte Carlo. Accepted at Eurographics 2025.">
  <meta name="twitter:card" content="player">
  <meta name="twitter:player" content="https://www.youtube.com/embed/Y791SlodLOs?vq=hd1080&showinfo=0">
  <meta name="twitter:player:width" content="1280">
  <meta name="twitter:player:height" content="720">
  <meta name="twitter:image" content="https://mishok43.github.io/nirc/static/images/TeaserNew.jpg">

  <!-- Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Neural Two-Level Monte Carlo Real-Time Rendering",
    "description": "Efficient real-time global illumination rendering using Neural Incident Radiance Cache combined with Two-Level Monte Carlo",
    "author": [
      {
        "@type": "Person",
        "name": "Mikhail Dereviannykh",
        "url": "http://mishok43.com"
      },
      {
        "@type": "Person",
        "name": "Dmitrii Klepikov",
        "url": "https://www.linkedin.com/in/ibvfteh/"
      },
      {
        "@type": "Person",
        "name": "Johannes Hanika",
        "url": "https://jo.dreggn.org/home/"
      },
      {
        "@type": "Person",
        "name": "Carsten Dachsbacher"
      }
    ],
    "publisher": {
      "@type": "Organization",
      "name": "Karlsruhe Institute of Technology",
      "url": "https://www.kit.edu"
    },
    "datePublished": "2025",
    "isPartOf": {
      "@type": "Periodical",
      "name": "Computer Graphics Forum",
      "publisher": {
        "@type": "Organization",
        "name": "Eurographics"
      }
    },
    "video": {
      "@type": "VideoObject",
      "name": "Neural Two-Level Monte Carlo Real-Time Rendering",
      "description": "Demonstration of our real-time global illumination rendering method",
      "thumbnailUrl": "https://mishok43.github.io/nirc/static/images/TeaserNew.jpg",
      "embedUrl": "https://www.youtube.com/embed/Y791SlodLOs",
      "uploadDate": "2025"
    }
  }
  </script>

  <title>Neural Two-Level Monte Carlo Real-Time Rendering | Eurographics 2025</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="image_src" href="https://mishok43.github.io/nirc/static/images/TeaserNew.jpg"/>

  <!-- MathJax -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1 publication-title">Neural Two-Level Monte Carlo Real-Time Rendering</h1>
      <div class="is-size-5 publication-authors">
        <!-- 
        Authors:
        Mikhail Dereviannykh, Dmitrii Klepikov, Johannes Hanika, Carsten Dachsbacher
        Johannes: https://jo.dreggn.org/home/
        
        -->
        <span class="author-block"><b><a href="http://mishok43.com">Mikhail Dereviannykh</a></b>,</span>
        <span class="author-block"><a href="https://www.linkedin.com/in/ibvfteh/">Dmitrii Klepikov</a>,</span>
        <span class="author-block"><a href="https://jo.dreggn.org/home/">Johannes Hanika</a>,</span>
        <span class="author-block">Carsten Dachsbacher</span>


      </div>
      <div class="is-size-5">
        Karlsruhe Institute of Technology<br>
        <b>Eurographics, 2025 - Computer Graphics Forum</b>
        <br>
        <p>
          Received ‚≠ê<strong>"Best Paper Honorable Mention"</strong>‚≠ê
        </p>
        <p>
          To be presented at <b>SIGGRAPH 2025</b>‚≠ê
        </p>
      </div>
      
      <br>
      
      <div class="publication-links">
        <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70050" class="button is-dark is-rounded">Paper</a>
        <a href="https://github.com/Mishok43/NIRCPython" class="button is-dark is-rounded">Code</a>
        <a href="static/pdfs/Slides_wo_videos.pdf" class="button is-dark is-rounded">Slides (w/o videos)</a>
        <a href="https://bwsyncandshare.kit.edu/s/bzAEZzqqw42ExNJ" class="button is-dark is-rounded">High-Res Video</a>
        <a href="https://bwsyncandshare.kit.edu/s/tizLCRYD5zorcif" class="button is-dark is-rounded">Low-Res Video</a>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Images Section -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <img src="static/images/TeaserNew.svg" alt="Teaser Main Image" style="width:100%">
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column">
        <!-- First Row -->
        <div class="columns is-centered is-mobile is-multiline mb-0" style="width:100%; margin:0 auto;">
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/0Reference.jpg" style="width:100%; image-rendering: pixelated;">
            
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/0PT.jpg" style="width:100%; image-rendering: pixelated;">
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/0OurBiased.jpg" style="width:100%; image-rendering: pixelated;">
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/0NRC.jpg" style="width:100%; image-rendering: pixelated;">
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/0OurUnbiased.jpg" style="width:100%; image-rendering: pixelated;">
          </div>
        </div>
        <!-- Second Row -->
        <div class="columns is-centered is-mobile is-multiline mt-0" style="width:100%; margin:0 auto;">
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/1Reference.jpg" style="width:100%; image-rendering: pixelated;">
            <p class="has-text-centered is-size-7-mobile">Reference</p>
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/1PT.jpg" style="width:100%; image-rendering: pixelated;">
            <p class="has-text-centered is-size-7-mobile">PT [<span style="color: rgba(90, 186, 179, 1)">Unbiased</span>]</p>
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/1OurBiased.jpg" style="width:100%; image-rendering: pixelated;">
            <p class="has-text-centered is-size-7-mobile">Ours [<span style="color: rgba(244, 112, 112, 1)">Biased</span>]</p>
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/1NRCBiased.jpg" style="width:100%; image-rendering: pixelated;">
            <p class="has-text-centered is-size-7-mobile"><a href="https://research.nvidia.com/publication/2021-06_real-time-neural-radiance-caching-path-tracing">NRC</a> [<span style="color: rgba(244, 112, 112, 1)">Biased</span>]</p>
          </div>
          <div class="column is-one-fifth-desktop is-one-fifth-tablet is-2-mobile" style="padding: 0.2rem;">
            <img src="static/images/1OurUnbiased.jpg" style="width:100%; image-rendering: pixelated;">
            <p class="has-text-centered is-size-7-mobile">Ours [<span style="color: rgba(90, 186, 179, 1)">Unbiased</span>]</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- TLTR Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <p style="background: linear-gradient(45deg, #FF6B6B, #4ECDC4); padding: 20px; border-radius: 10px; color: white; text-shadow: 1px 1px 2px rgba(0,0,0,0.2);">
        <strong style="color: #FFE66D;">TLTR:</strong> We present <span style="color: #FFE66D;">Neural Incident Radiance Cache (NIRC)</span> for efficient fully-fused neural network-based Global Illumination integration, combined with <span style="color: #FFE66D;">Two-Level Monte Carlo</span> for unbiased results - achieving variance reduction and performance improvement better than previous methods.
      </p>
    </div>
  </div>
</section>

<!-- Abstract Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <p class="content has-text-justified">
      We introduce an efficient <strong>Two-Level Monte Carlo</strong> (subset of Multi-Level Monte Carlo, MLMC) estimator for real-time renderingof scenes with global illumination. Using MLMC we split the shading integral into two parts: the radiance cache integral andthe residual error integral that compensates for the bias of the first one. For the first part, we developed the <strong>Neural Incident Radiance Cache (NIRC)</strong> leveraging the power of tiny neural networks [MRNK21] as a building block, which is trained on thefly. The cache is designed to provide a fast and reasonable approximation of the incident radiance: an evaluation takes <strong>2-25√ó</strong> less compute time than a path tracing sample. This enables us to estimate the radiance cache integral with a high number ofsamples and by this achieve faster convergence. For the residual error integral, we compute the difference between the NIRCpredictions and the unbiased path tracing simulation. Our method makes no assumptions about the geometry, materials, orlighting of a scene and has only few intuitive hyper-parameters. We provide a comprehensive comparative analysis in differentexperimental scenarios. Since the algorithm is trained in an on-line fashion, it demonstrates significant noise level reductioneven for dynamic scenes and can easily be combined with other noise reduction techniques    </p>
  </div>
</section>

<!-- Video Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <div class="has-text-centered">
        <div class="publication-video">
          <iframe width="100%" height="400" src="https://www.youtube.com/embed/Y791SlodLOs?vq=hd1080&showinfo=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <p class="is-size-6 mt-2">
          Note: Video compression reduces visible noise. For accurate noise reduction comparison, see the <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70050">paper</a> or download the high-quality video <a href="https://bwsyncandshare.kit.edu/s/bzAEZzqqw42ExNJ">here</a>.
        </p>
      </div>
    </div>
  </div>
</section>


<!-- Method Overview Figure Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <h2 class="title is-3 has-text-centered">We've already got NRC... why NIRC?</h2>
        <br>
        <figure class="image">
          <div class="columns">
            <div class="column is-6">
              <img src="static/images/BiasedExpl.svg" alt="Method Overview" style="width: 100%; height: auto;">
            </div>
            <div class="column is-6">
              <div class="content has-text-justified">
                <p>
                  Our <em>Neural Incident Radiance Cache (NIRC)</em> learns <strong>incoming light</strong> from all directions in real-time, unlike NRC [MRNK21] which predicts <strong>outgoing light</strong>. This key difference enables several advantages:
                  <li>‚ö°Immediate cache invokation at primary surface w/o additional rays, but with BSDF properties preservation üé®</li>
                  <li>‚ö°Multiresolution neural hash-grid sampling costs amortized across all directional samples (~70% time of original NRC)</li>
                  <li>üöÄWith inlined invokations performance scales directly with tensor-core compute rather than bandwidth, benefiting from the recent GPU-trends and low-precision TFLOPs</li>
                  <br>
                  So, <strong>if many samples invoked, a NIRC's one is cheaper in 5-10x times compared to NRC's one on average.</strong></li>
                </ul>
              </div>
            </div>
          </div>

          <div style="margin-bottom: 1%;"></div>


          <div class="columns">
            <div class="column is-6">
              <figure class="image" >
                <img src="static/images/performance.svg" alt="Performance Comparison" style="width: 100%; height: auto;">
                <figcaption class="has-text-centered mt-2">Performance study with the Bistro Exterior scene
                  rendered on an RTX 3080 at 1080p. Path-Tracing vs NRC vs NIRC (Ours) with a few low-level optimizations. </figcaption>
              </figure>
            </div>
            <div class="column is-6">
              <figure class="image" style="margin-top: 4%">
                <video width="100%" height="auto" autoplay loop muted playsinline>
                  <source src="static/videos/cache.mp4" type="video/mp4">
                </video>
                <figcaption class="has-text-centered mt-2">On-the-fly NIRC visualization for an arbitrary point in the Sponza scene</figcaption>
              </figure>
            </div>
          </div>

          <!-- Cache Quality vs. MLP Depth Section -->
          <div class="section" style="padding-top: 0;">
            <div class="container is-max-desktop">
              <div class="content has-text-justified">
                <h3 class="title is-4 has-text-centered">Scalability from tensor-core compute üíª</h3>
              
                <div class="columns">
                  <div class="column is-5 has-text-centered" style="flex: 0 0 40%; max-width: 40%;">
                    <img src="static/images/Marked_CQ_CornelBox_Reference.jpg" alt="Marked Cache Quality Reference" style="width:100%; max-width:100%;">
                    <div class="is-size-6 mt-2"><b>Reference</b></div>
                    <div class="is-size-7 mt-1" style="color:#888; max-width: 220px; margin: 0 auto;">
                      For more details and full context, see Figure 15 in the paper, as it doesn't always scale well for noisy scenes.<br>
                    </div>
                  </div>
                  <div class="column is-7" style="flex: 0 0 60%; max-width: 60%;">
                    <div class="columns is-mobile is-multiline is-centered" style="margin-bottom: 0.5em;">
                      
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_0_2Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">2 Layers <br>MSE: 0.56, 0.84ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_0_4Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">4 Layers <br>MSE: 0.27, 1.24ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_0_6Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">6 Layers <br>MSE: 0.14, 1.64ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_0_Reference.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">Reference</div>
                      </div>
                    </div>
                    <div class="columns is-mobile is-multiline is-centered" style="margin-bottom: 0.5em;">
                      
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_1_2Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">2 Layers <br>MSE: 0.23, 0.84ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_1_4Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">4 Layers <br>MSE: 0.21, 1.24ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_1_6Layers.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">6 Layers <br>MSE: 0.13, 1.64ms</div>
                      </div>
                      <div class="column is-one-quarter has-text-centered">
                        <img src="static/images/CQ_CornelBox_1_Reference.jpg" style="width:100%; max-width:180px;">
                        <div class="is-size-7">Reference</div>
                      </div>
                    </div>
                    <div class="is-size-7 has-text-right mt-2" style="color:#888;">All timings on RTX 3080</div>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <h2 class="title is-3 has-text-centered">ü§î Two-Level Monte Carlo? </h2>
          <br>
        <figure class="image">
          <div class="columns">
            <div class="column is-6">
              <img src="static/images/UnbiasedExpl.svg" alt="Unbiased Explanation" style="width: 100%; height: auto;">
            </div>
            <div class="column is-6">
              <div class="content has-text-justified">
                <p>
                  We split the rendering estimator into two parts: the <strong><em style="color:#A07B3F;">Cache-Based Estimator</em></strong> and the <strong><em style="color:#2CA148;">Residual Error Estimator</em></strong> that compensates for the bias of the first one.
                  It's similar to Neural Control Variates (NCV) [MRKN20], but NIRC does not need to predict the integral itself ‚üπ <em>no neural network architectural constraints</em>!
                  <br>
                  <br>
                  <strong>So, we can use NIRC with <span style="color: #2CA148;">no bias</span> and get a reasonable cache quality in 10-20 frames vs 100-1000 for NCV.</strong> Yes, we need to integrate over directions... but it's just <strong>0.5-1.5ms/sample at 1080p on a RTX 4080. </strong>!
              </div>
            </div>
          </div>

          <div class="content has-text-centered mt-4">
              <div class="has-text-centered" style="position: relative; max-width: 700px; margin: 0 auto;">
                <div style="position: relative; overflow: hidden; max-height: 420px;">
                  <div id="equation-spoiler" style="display: flex; flex-direction: column; align-items: center; gap: 0.2em; position: relative;">
                    <div style="display: flex; align-items: center; gap: 1em;">
                      <span style="min-width: 170px; color: #A07B3F; text-align: right; font-weight: bold;">Cache-Based Estimator:</span>
                      <span style="text-align: left;">
                        \[
                        {\color{#A07B3F}{\hat{L}_{c}(x, \omega_{o})}} \approx \frac{1}{N_{c}} \sum_{i=1}^{N_{c}} \frac{L_{nirc}(x, \omega_{i}, \phi,\mathbf{w})f_{r}(x,\omega_{i},\omega_{o})\cos\theta_{i}}{p(\omega_{i})}\omega_{o})
                        \]
                      </span>
                    </div>
                    <div style="display: flex; align-items: center; gap: 1em;">
                      <span style="min-width: 170px; color: #2CA148; text-align: right; font-weight: bold;">Residual Error Estimator:</span>
                      <span style="text-align: left;">
                        
                        \[
                        {\color{#2CA148}{\hat{L}_{r}(x, \omega_{o})}} \approx \frac{1}{N_{r}} \sum_{i=1}^{N_{r}}
                        \frac{(L_{i}(x, \omega_{i})-L_{nirc}(x, \omega_{i},
                        \phi,\mathbf{w}))f_{r}(x,\omega_{i},\omega_{o})\cos\theta_{i}}{p(\omega_{i})}
                        \]
                      </span>
                    </div>
                    
                    <div style="display: flex; align-items: center; gap: 1em;">
                      <span style="min-width: 170px; color: #444; text-align: right; font-weight: bold;">Unbiased Estimator:</span>
                      <span style="text-align: left;">
                        \[
                        \hat{L}_{o}(x, \omega_{o}) \approx  L_{e}(x, \omega_{o}) + \hat{L}_{nee}(x, \omega_{o}) + {\color{#A07B3F}{\hat{L}_{c}(x, \omega_{o})}} + {\color{#2CA148}{\hat{L}_{r}(x, \omega_{o})}}
                        \]
                      </span>
                    </div>
                  </div>
                </div>
                <div id="fade-overlay" style="position: absolute; left: 0; right: 0; top: 20%; bottom: 0; pointer-events: none; background: linear-gradient(to bottom, rgba(255,255,255,0) 0%, rgba(255,255,255,1) 90%); transition: opacity 0.3s;"></div>
              </div>
              <button id="show-more-btn" class="button is-small is-light" style="margin-top: 1em; position: relative; z-index: 2;">Show me the math</button>
              <script>
                document.getElementById('show-more-btn').onclick = function() {
                  document.getElementById('fade-overlay').style.opacity = 0;
                  setTimeout(function() {
                    document.getElementById('fade-overlay').style.display = 'none';
                    document.getElementById('show-more-btn').style.display = 'none';
                  }, 300);
                };
              </script>
          </div>

          <style>
            /* overall two-column container */
            .scene-container {
              display: flex;
              align-items: flex-start;  /* tops aligned */
              gap: 5%;                /* space between panels */
              margin: 1em 0;
            }
          
            /* left panel: fixed width, centered contents */
            .scene-left {
              width: 200px;             /* = max-width of image */
              display: flex;
              flex-direction: column;
              align-items: center;
            }
          
            /* smaller title */
            h2.scene-title {
              font-size: 1.5rem;        /* Bulma is-4 */
              text-align: center;
              margin-bottom: 1rem;
            }
          
            /* Prev/Name/Next row */
            .scene-controls {
              display: flex;
              align-items: center;
              gap: 0.5rem;
              margin-bottom: 0.5rem;
            }
            .scene-controls button {
    background: rgba(0, 0, 0, 0.1);  /* minimal light gray background */
    border: none;
    font-size: 0.9rem;      /* slightly smaller arrows */
    padding: 0.1em 0.4em;   /* tighter padding */
    cursor: pointer;
    border-radius: 3px;     /* subtle rounded corners */
  }
            #scene-name {
    font-weight: bold;
    font-size: 0.95rem;
    min-width: 100px;
    white-space: nowrap;    /* keep on one line */
    text-align: center;
  }

          
            /* plot + FLIP label */
            .scene-plot-row {
              display: flex;
              align-items: center;
            }
            .scene-flip-label {
              writing-mode: vertical-rl;
              transform: rotate(180deg);
              margin-right: 8px;
              font-weight: bold;
              font-size: 0.9rem;
            }
            #scene-plot {
              max-width: 200px;
              width: 100%;
              height: auto;
            }
          
            /* x-axis label under image only */
            .scene-xlabel {
              width: 200px;             /* same as img max-width */
              text-align: center;
              margin-top: 4px;
              font-size: 0.9rem;
              margin-right: -45%;
            }
          
            /* right panel: fluid */
            .scene-right {
              flex: 1;
            }
          </style>
          
          <!-- smaller title -->
          <h2 class="title is-3 has-text-centered">So, does it mean that NIRC is better than NRC? </h2>
          
          
          <div class="scene-container">
            <!-- LEFT -->
            <div class="scene-left">
              <div class="scene-controls">
                <div style="margin-left: 42%;">
                  <span id="scene-name"> Bistro Exterior</span>
                  <div style="margin-left: 17%;">
                  <button id="prev-scene">prev</button>
                  <button id="next-scene">next</button>
                  </div>
                </div>
              </div>
          
              <div class="scene-plot-row">
                <span class="scene-flip-label">Bias</span>
                <img
                  id="scene-plot"
                  src="static/images/BistroDirection_averagepath_bias.svg"
                  alt="scene plot"
                >
              </div>
          
              <div class="scene-xlabel">Indirect Bounces</div>
              
              
            </div>
          
            <!-- RIGHT -->
            <div class="scene-right">
              <div class="content">
                <p>
                  <br>
                  <br>
                  Our research shows that the choice between NIRC and NRC depends on your specific requirements. Here's a rule of thumb:
                </p>
                <ul>
                  <li>
                    <strong style="color: #2CA148;">Zero-bias requirement:</strong> Use <em>NIRC</em> with <em>Two-Level Monte Carlo</em>. Note that this may increase variance in complex areas like dense foliage (üå≥ trees, bushes, etc).
                  </li>
                  <li>
                    <strong style="color: #A07B3F;">Performance maximization:</strong> Invoke <em>NRC</em> at \(x_i\) if it provides sufficient quality. Switch to <em>NIRC</em> if you encounter poor GI, material property preservation issues or visible hash-grid artifacts ‚Äì <strong>NIRC will save you unnecessary ray bounces that NRC would require otherwise.</strong> If both methods fail, perform another bounce and repeat the logic for \(x_{i+1}\).
                  </li>
                </ul>
                <p>
                  <span style="font-size: 0.85rem; color: #537B8D;"><strong style="font-size: 0.85rem; color: #537B8D;">  NRC </strong></span> | <span style="font-size: 0.85rem; color: #9B5C6F;"><strong style="font-size: 0.85rem; color: #9B5C6F;">NIRC</strong></span> <em style="font-size: 0.85rem;">- converged renders</em>
                  <br>
                  You can see how much less indirect rays you need to trace by employing <em>NIRC</em> if the render quality satisfies your requirements.
                </p>
              </div>
            </div>
          </div>
          
          <script>
            const scenes = [
              { name: 'Bistro Exterior', img: 'static/images/BistroDirection_averagepath_bias.svg' },
              { name: 'The White Room',  img: 'static/images/the-white-room_averagepath_bias.svg' },
              { name: 'Sponza Specular',  img: 'static/images/SponzaSpecular_averagepath_bias.svg' },
              { name: 'Country Kitchen',  img: 'static/images/CountryKitchen_averagepath_bias.svg' }
            ];
            let sceneIdx = 0;
            function updateScene() {
              const plot = document.getElementById('scene-plot');
              const name = document.getElementById('scene-name');
              plot.src = scenes[sceneIdx].img;
              name.textContent = scenes[sceneIdx].name;
            }
            document.getElementById('prev-scene').onclick = () => {
              sceneIdx = (sceneIdx - 1 + scenes.length) % scenes.length;
              updateScene();
            };
            document.getElementById('next-scene').onclick = () => {
              sceneIdx = (sceneIdx + 1) % scenes.length;
              updateScene();
            };
          </script>
          
          

        </div>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{https://doi.org/10.1111/cgf.70050,
      author = {Dereviannykh, Mikhail and Klepikov, Dmitrii and Hanika, Johannes and Dachsbacher, Carsten},
      title = {Neural Two-Level Monte Carlo Real-Time Rendering},
      journal = {Computer Graphics Forum},
      volume = {44},
      number = {2},
      pages = {e70050},
      keywords = {CCS Concepts, ‚Ä¢ Computing methodologies ‚Üí Ray tracing, Neural networks},
      doi = {https://doi.org/10.1111/cgf.70050},
      url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.70050},
      eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.70050},
      abstract = {Abstract We introduce an efficient Two-Level Monte Carlo (subset of Multi-Level Monte Carlo, MLMC) estimator for real-time rendering of scenes with global illumination. Using MLMC we split the shading integral into two parts: the radiance cache integral and the residual error integral that compensates for the bias of the first one. For the first part, we developed the Neural Incident Radiance Cache (NIRC) leveraging the power of tiny neural networks [MRNK21] as a building block, which is trained on the fly. The cache is designed to provide a fast and reasonable approximation of the incident radiance: an evaluation takes 2‚Äì25 √ó less compute time than a path tracing sample. This enables us to estimate the radiance cache integral with a high number of samples and by this achieve faster convergence. For the residual error integral, we compute the difference between the NIRC predictions and the unbiased path tracing simulation. Our method makes no assumptions about the geometry, materials, or lighting of a scene and has only few intuitive hyper-parameters. We provide a comprehensive comparative analysis in different experimental scenarios. Since the algorithm is trained in an on-line fashion, it demonstrates significant noise level reduction even for dynamic scenes and can easily be combined with other noise reduction techniques.}
      }
      
      </code></pre>
  </div>
</section>
<!--End BibTex citation -->





<footer class="footer">
<div class="container">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">

        <p>
          This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>

      </div>
    </div>
  </div>
</div>
</footer>

</body>
</html>
